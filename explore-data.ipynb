{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "542ade4d-9208-4b5c-aa01-51b502d50ab8",
   "metadata": {},
   "source": [
    "# Red Hat OpenShift Data Science + Starburst Galaxy:  <br>  Access and Explore your Data\n",
    "\n",
    "## Introduction\n",
    "**Red Hat OpenShift Data Science**, a managed cloud platform for Data Scientists and Developers of intelligent applications, supports the full Machine Learning lifecycle by providing a robust, scalable platform and a flexible, interactive environment for teams to do their work. **Starburst Galaxy**, based on open source Trino (formerly PrestoSQL), is a managed service providing a single point of access to your data without having to move it to a central repository. **Starburst Galaxy** focuses on the first, and often most difficult problem teams face when starting a new project - **The Acquisition and Preparation of Data**. \n",
    "\n",
    "This demonstration illustrates how quickly a Data Scientist can access data and pull it into the Red Hat OpenShift Data Science Jupyter environment using Starburst Galaxy.\n",
    "\n",
    "\n",
    "**Figure:** Machine Learning Lifecycle\n",
    "\n",
    "![MLLC](files/ml-lifecycle-desktop.svg)\n",
    "\n",
    "\n",
    "\n",
    "**Useful links**:\n",
    "* [Red Hat OpenShift Data Science](https://www.redhat.com/en/technologies/cloud-computing/openshift/openshift-data-science)\n",
    "* [Starburst Galaxy](https://www.starburst.io/platform/starburst-galaxy/)\n",
    "* [AI/ML on OpenShift](https://cloud.redhat.com/learn/topics/ai-ml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc700d-18bb-4584-b8dc-a9b5fff21430",
   "metadata": {},
   "source": [
    "## Installing Required Packages\n",
    "Red Hat OpenShift Data Science provides images loaded with popular Open Source Data Science packages. These are also the notebook images we use when building our own intelligent applications. \n",
    "\n",
    "While these images typically have everything we need, we can always layer in specific package requirements using `pip` and a `requirements.txt` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d76ad-489d-4237-99a0-04fcd73b25eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917fa02-3309-4e0f-bbe3-fb54cb045cde",
   "metadata": {},
   "source": [
    "## Environment Initialization\n",
    "\n",
    "### Import packages and environment variables\n",
    "Let's import the packages we installed in the previous step and a simple helper function included in `helper.py`. Let's also assign the environment variables we included while spawning our notebook. This way, we won't accidentally expose sensitive connection information!\n",
    "\n",
    "Lastly, we use these variables and the `trino.dbapi.connect` function to create our Connection object. \n",
    "\n",
    "### A note on security\n",
    "Please ensure your Starburst Galaxy cluster meets your specific security requirements. \n",
    "There are three general areas to consider: \n",
    "- Securing access to the cluster\n",
    "- Securing internal traffic within the cluster\n",
    "- Securing data source connections\n",
    "\n",
    "By default, Starburst Galaxy client access is secured using HTTPS/TLS.\n",
    "Authentication can be configured using your preffered authentication provider, i.e. LDAP. \n",
    "Lastly, enable authorization and access controls. \n",
    "**Source**: [Security Overview](https://docs.starburst.io/356-e/security/overview.html#security-client)\n",
    "\n",
    "For the purposes of this demonstration, let's assume HTTPS/TLS and Basic Authentication is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6830c-e694-498d-bbd9-f5e72c3b5e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from helper import get_sql \n",
    "import trino\n",
    "\n",
    "TRINO_USERNAME = os.environ.get('TRINO_USERNAME')\n",
    "TRINO_PASSWORD = os.environ.get('TRINO_PASSWORD')\n",
    "TRINO_HOSTNAME = os.environ.get('TRINO_HOSTNAME')\n",
    "TRINO_PORT     = os.environ.get('TRINO_PORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65788218-cd50-4689-8bf6-8bba06607aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = trino.dbapi.connect(\n",
    "    host=TRINO_HOSTNAME,\n",
    "    port=TRINO_PORT,\n",
    "    user=TRINO_USERNAME,\n",
    "    http_scheme='https',\n",
    "    auth=trino.auth.BasicAuthentication(TRINO_USERNAME, TRINO_PASSWORD),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c48f7-7510-4fd6-a5db-2754d21fa2ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## What is Starburst Galaxy and how does it work? \n",
    "Starburst Galaxy is an incredibly efficient layer sitting between the data consumer and our data sources. It brings our data together so we can query sources individually or join them together in ways that previously required extensive ETL processes.\n",
    "\n",
    "Let's use our connection object and SQL statements to interact with Starburst Galaxy. \n",
    "\n",
    "The following SQL statements help us understand our data sources:\n",
    "* `'SHOW CATALOGS'` shows the data sources available to us at this time,\n",
    "* `'SHOW SCHEMAS'` indicates how data tables are organized, and \n",
    "* `'SHOW TABLES'` exposes datasets within a catalog and schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04fdaa-1a32-4f11-b70b-86e7c42c1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SHOW CATALOGS'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c124cd-17a6-4c22-81cb-cc7dc5cbaf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SHOW SCHEMAS from tpch'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f52505-2b3c-4b12-9816-0740ab14bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SHOW TABLES FROM tpch.sf1'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6988a2-5c67-4660-894b-f770b1a6cdbe",
   "metadata": {},
   "source": [
    "**Please note**:\n",
    "Our example here only includes the sample datasets shipped with Starburst Galaxy. Your data sources will show up under `'SHOW CATALOGS'` after their respective connectors are configured in your catalog.\n",
    "\n",
    "**Some useful terminology**:\n",
    "* **data source** - your data stored in a database, bucket, or other. Starburst has connectors for most sources already. \n",
    "* **connector** - connectors configure your catalog. They give you access to your data sources. They are similar to drivers, in a way.\n",
    "* **catalog** - defines schemas and properties of connections so Galaxy knows how to query your data.\n",
    "* **schema**  - how your tables are organized.\n",
    "* **table**   - similar to tables in a relational database. A set of rows and columns representing your data based on connector properties.\n",
    "* **tpch**    - a synthetic dataset used to benchmark systems. We are using it here for a sample dataset.\n",
    "\n",
    "**Useful links**:\n",
    "[Starburst Documentation](https://docs.starburst.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb982c0-c31e-401d-92ec-ee94328f2aa8",
   "metadata": {},
   "source": [
    "## Accessing Data\n",
    "We've seen the data sources we have access to (CATALOGS), their associated SCHEMAS, and some data tables from tpch.  Let's run some actual queries to access the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927aedfc-5055-4fcd-9540-c3991255c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SELECT * FROM tpch.sf1.customer limit 40'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550abbd7-7adb-4729-aba3-57f8645a4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT * FROM tpch.sf1.orders limit 40\"\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c79010f-97f7-4f45-960f-6a745b218cf5",
   "metadata": {},
   "source": [
    "And like other relational databases, we can join tables together for more useful views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d6a0b1-287c-4439-8296-892e5f364621",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "\n",
    "SELECT \n",
    "    c.custkey, \n",
    "    c.name, \n",
    "    c.nationkey, \n",
    "    c.mktsegment, \n",
    "    o.totalprice, \n",
    "    o.orderdate \n",
    "FROM tpch.sf1.customer c \n",
    "JOIN tpch.sf1.orders o ON c.custkey = o.custkey \n",
    "ORDER BY o.orderdate DESC\n",
    "limit 40\n",
    "\n",
    "\"\"\"\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8038183-5bdf-4033-8d58-9a5376189381",
   "metadata": {},
   "source": [
    "## What's Next\n",
    "Starburst Galaxy's real power is its ability to access multiple data sources using a single query and push processing down to the analytical store housing your data. However, we must first connect a data source to your Starburst Galaxy cluster which is outside the scope of our tutorial today.  \n",
    "\n",
    "Let me highlight this capability with a simple example. Let's assume you connect a data source containing marketing campaign data to your catalog. From there, you could run the following hypothetical query joining your `email` marketing compaign to your `customer` and `order` tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cecf53-2d6d-4968-8d39-1a206d99441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is illustrative only\n",
    "sql = \"\"\"\n",
    "\n",
    "SELECT \n",
    "    c.custkey, \n",
    "    c.name, \n",
    "    c.mktsegment, \n",
    "    SUM(o.totalprice) as sum_ordered,\n",
    "    e.open_rate\n",
    "FROM tpch.sf1.customer c \n",
    "JOIN tpch.sf1.orders o ON c.custkey = o.custkey \n",
    "JOIN marketing.campaigns.email e ON e.custkey = c.custkey\n",
    "GROUP BY c.custkey\n",
    "ORDER BY o.orderdate DESC\n",
    "limit 40\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7ec73-3bc6-4862-87d2-fe5b0b32700c",
   "metadata": {},
   "source": [
    "**That's two disparate data sources behaving as if they are in the same data warehouse!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d0523b-a813-41b6-a247-bdaabc510eb1",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "There's no question that this demo barely scratches the surface of what **Red Hat OpenShift Data Science** and **Starburst Galaxy** have to offer. We hope it has shown you, at least at a highlevel, how these tools enable data acccess and exploration so Data Science teams can quickly advance to the next phase in the Machine Learning Lifecycle - **Model Building**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
